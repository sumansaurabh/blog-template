<div class="container">
  
  <button type="button" class="btn btn-info set-block-b" data-toggle="collapse" data-target="#naive_bayes">Lesson 1: Naive Bayes</button>
  <div id="naive_bayes" class="collapse">
    <br>
    <a href="" ng-click="click_view('nb-exercise1', 'naive_bayes')"><h3>Exercise 1: GaussianNB Deployment on Terrain Data</h3></a>
    <div ng-if="curr_view==='nb-exercise1'">
      <h4 class="h4-code"> class_vis.py</h4>
      <pre>
        <code class="python">
          #!/usr/bin/python

          #from udacityplots import *
          import matplotlib 
          matplotlib.use('agg')

          import matplotlib.pyplot as plt
          import pylab as pl
          import numpy as np

          import base64
          import json
          import subprocess

          def prettyPicture(clf, X_test, y_test):
              x_min = 0.0; x_max = 1.0
              y_min = 0.0; y_max = 1.0

              # Plot the decision boundary. For that, we will assign a color to each
              # point in the mesh [x_min, m_max]x[y_min, y_max].
              h = .01  # step size in the mesh
              xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
              Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])

              # Put the result into a color plot
              #matplotlib inline
              Z = Z.reshape(xx.shape)
              plt.xlim(xx.min(), xx.max())
              plt.ylim(yy.min(), yy.max())

              plt.pcolormesh(xx, yy, Z, cmap=pl.cm.seismic)

              # Plot also the test points
              grade_sig = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==0]
              bumpy_sig = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==0]
              grade_bkg = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==1]
              bumpy_bkg = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==1]

              plt.scatter(grade_sig, bumpy_sig, color = "b", label="fast")
              plt.scatter(grade_bkg, bumpy_bkg, color = "r", label="slow")
              plt.legend()
              plt.xlabel("bumpiness")
              plt.ylabel("grade")

              #plt.savefig("test.png")
              
          def output_image(name, format, bytes):
              image_start = "BEGIN_IMAGE_f9825uweof8jw9fj4r8"
              image_end = "END_IMAGE_0238jfw08fjsiufhw8frs"
              data = {}
              data['name'] = name
              data['format'] = format
              data['bytes'] = base64.encodestring(bytes)
              print image_start+json.dumps(data)+image_end
        </code>
      </pre>
      <h4 class="h4-code">prep_terrain_data.py</h4>
      <pre>
        <code class="python">
          #!/usr/bin/python
          import random


          def makeTerrainData(n_points=1000):
          ### make the toy dataset
              random.seed(42)
              grade = [random.random() for ii in range(0,n_points)]
              bumpy = [random.random() for ii in range(0,n_points)]
              error = [random.random() for ii in range(0,n_points)]
              y = [round(grade[ii]*bumpy[ii]+0.3+0.1*error[ii]) for ii in range(0,n_points)]
              for ii in range(0, len(y)):
                  if grade[ii]>0.8 or bumpy[ii]>0.8:
                      y[ii] = 1.0

          ### split into train/test sets
              X = [[gg, ss] for gg, ss in zip(grade, bumpy)]
              split = int(0.75*n_points)
              X_train = X[0:split]
              X_test  = X[split:]
              y_train = y[0:split]
              y_test  = y[split:]

              grade_sig = [X_train[ii][0] for ii in range(0, len(X_train)) if y_train[ii]==0]
              bumpy_sig = [X_train[ii][1] for ii in range(0, len(X_train)) if y_train[ii]==0]
              grade_bkg = [X_train[ii][0] for ii in range(0, len(X_train)) if y_train[ii]==1]
              bumpy_bkg = [X_train[ii][1] for ii in range(0, len(X_train)) if y_train[ii]==1]

          #    training_data = {"fast":{"grade":grade_sig, "bumpiness":bumpy_sig}
          #            , "slow":{"grade":grade_bkg, "bumpiness":bumpy_bkg}}


              grade_sig = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==0]
              bumpy_sig = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==0]
              grade_bkg = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==1]
              bumpy_bkg = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==1]

              test_data = {"fast":{"grade":grade_sig, "bumpiness":bumpy_sig}
                      , "slow":{"grade":grade_bkg, "bumpiness":bumpy_bkg}}

              return X_train, y_train, X_test, y_test
          #    return training_data, test_data
        </code>
      </pre>
      <h4 class="h4-code">ClassifyNB.py</h4>
      <pre>
        <code class="python">
          def classify(features_train, labels_train):   
          ### import the sklearn module for GaussianNB
          ### create classifier
          ### fit the classifier on the training features and labels
          ### return the fit classifier
          
              
          ### your code goes here!
          from sklearn.naive_bayes import GaussianNB
          clf = GaussianNB()
          clf.fit(features_train, labels_train)
          return clf
        </code>
      </pre>
      <h4 class="h4-code">studentMain.py</h4>
      <pre>
        <code class="python">
          #!/usr/bin/python

          """ Complete the code in ClassifyNB.py with the sklearn
              Naive Bayes classifier to classify the terrain data.
              
              The objective of this exercise is to recreate the decision 
              boundary found in the lesson video, and make a plot that
              visually shows the decision boundary """


          features_train, labels_train, features_test, labels_test = makeTerrainData()

          ### the training data (features_train, labels_train) have both "fast" and "slow" points mixed
          ### in together--separate them so we can give them different colors in the scatterplot,
          ### and visually identify them
          grade_fast = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==0]
          bumpy_fast = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==0]
          grade_slow = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==1]
          bumpy_slow = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==1]

          clf = classify(features_train, labels_train)

          ### draw the decision boundary with the text points overlaid
          prettyPicture(clf, features_test, labels_test)
          #output_image("test.png", "png", open("test.png", "rb").read())
        </code>
      </pre>
      <h3 class="h4-code">Output</h3>
      <img src="/img/images/GaussianNB.png">
    </div>
    <a href="" ng-click="click_view('nb-exercise2', 'naive_bayes')"><h3>Exercise 2: Calculating NB Accuracy</h3></a>
    <div ng-if="curr_view==='nb-exercise2'">
      <h4 class="h4-code">classify.py</h4>
      <pre>
        <code class="python">
          def NBAccuracy(features_train, labels_train, features_test, labels_test):
            """ compute the accuracy of your Naive Bayes classifier """
            ### import the sklearn module for GaussianNB
            from sklearn.naive_bayes import GaussianNB
            from sklearn.metrics import accuracy_score

            ### create classifier
            clf = GaussianNB()

            ### fit the classifier on the training features and labels
            clf.fit(features_train, labels_train)

            ### use the trained classifier to predict labels for the test features
            # method 1
            accuracy = clf.score(features_test, labels_test)
            
            # method 2
            pred = clf.predict(features_test)
            accuracy = accuracy_score(pred, labels_test)
            
            return accuracy
        </code>
      </pre>
      <h4 class="h4-code">studentCode.py</h4>
      <pre>
        <code class="python">
          features_train, labels_train, features_test, labels_test = makeTerrainData()

          def submitAccuracy():
              accuracy = NBAccuracy(features_train, labels_train, features_test, labels_test)
              return accuracy

          print submitAccuracy()
        </code>
      </pre>
      <h4 class="h4-code">Output</h4>
      <p>Output -: 0.884</p>
    </div>
    <a href="" ng-click="click_view('nb-exercise3', 'author_id_accuracy')"><h3>Exercise 3: Author ID Accuracy</h3></a>
    <div ng-if="curr_view==='nb-exercise3'">
      <h4 class="h4-code">nb_author_id.py</h4>
      <pre>
        <code class="python">
          #!/usr/bin/python

          """ 
              This is the code to accompany the Lesson 1 (Naive Bayes) mini-project. 

              Use a Naive Bayes Classifier to identify emails by their authors
              
              authors and labels:
              Sara has label 0
              Chris has label 1
          """

          import os
          os.chdir('C:/Users/Jeff/udacity/Intro_to_Machine_Learning/ud120-projects/naive_bayes')

          import sys
          from time import time

          sys.path.append("../tools/")
          from email_preprocess import preprocess


          ### features_train and features_test are the features for the training
          ### and testing datasets, respectively
          ### labels_train and labels_test are the corresponding item labels
          features_train, features_test, labels_train, labels_test = preprocess()




          #########################################################
          ### your code goes here ###
          from sklearn.naive_bayes import GaussianNB
          from sklearn.metrics import accuracy_score

          # the classifier
          clf = GaussianNB()

          # train
          t0 = time()
          clf.fit(features_train, labels_train)
          print "\ntraining time:", round(time()-t0, 3), "s"

          # predict
          t0 = time()
          pred = clf.predict(features_test)
          print "predicting time:", round(time()-t0, 3), "s"

          accuracy = accuracy_score(pred, labels_test)

          print '\naccuracy = {0}'.format(accuracy)
        </code>
      </pre>
      <h4 class="h4-code">Output</h4>
      <p>
        no. of Chris training emails: 7936<br>
        no. of Sara training emails: 7884<br>
        <br>
        training time: 1.33 s<br>
        predicting time: 0.203 s<br>

        accuracy = 0.973265073948<br>
      </p>
    </div>
  </div>

  <button type="button" class="btn btn-info set-block-b" data-toggle="collapse" data-target="#svm">Lesson 2: SVM</button>
  <div id="svm" class="collapse">
    <br>
    <a href="" ng-click="click_view('svm-exercise1', 'svm')"><h3>Exercise 1: SVM in SKlearn</h3></a>
    <div ng-if="curr_view==='svm-exercise1'">
      <h4 class="h4-code">SVM in SKlearn</h4>
      <pre>
        <code class="python">
          import sys
          sys.path.append("C:/Users/Jeff/udacity/Intro_to_Machine_Learning/ud120-projects/tools/")
          sys.path.append('C:/Users/Jeff/udacity/Intro_to_Machine_Learning/ud120-projects/choose_your_own')
          sys.path.append('C:/Users/Jeff/udacity/Intro_to_Machine_Learning/ud120-projects/svm')

          import os
          os.chdir('C:/Users/Jeff/udacity/Intro_to_Machine_Learning/ud120-projects/svm')


          from class_vis import prettyPicture
          from prep_terrain_data import makeTerrainData

          import sys
          import matplotlib.pyplot as plt
          import copy
          import numpy as np
          import pylab as pl

          from sklearn.metrics import accuracy_score


          features_train, labels_train, features_test, labels_test = makeTerrainData()


          ########################## SVM #################################
          from sklearn.svm import SVC

          def submitAccuracy():
              return accuracy_score(pred, labels_test)

          clf = SVC(kernel="linear")
          clf.fit(features_train, labels_train)
          pred = clf.predict(features_test)

          print accuracy_score(pred, labels_test)
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span> <span>0.92</span>
      </div>
    </div>

    <a href="" ng-click="click_view('svm-exercise2', 'svm')"><h3>Exercise 2: Kernel and Gamma</h3></a>
    <div ng-if="curr_view==='svm-exercise2'">
      <h4 class="h4-code">Kernel and Gamma</h4>
      <pre>
        <code class="python">
          clf = SVC(kernel="linear", gamma=1.0)
          clf.fit(features_train, labels_train)
          pred = clf.predict(features_test)

          %matplotlib inline
          prettyPicture(clf, features_test, labels_test)
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span> <span><img src="/img/images/kernel_gamma.png"></span>
      </div>
    </div>

    <a href="" ng-click="click_view('svm-exercise3', 'svm')"><h3>Exercise 3: SVM C Parameter</h3></a>
    <div ng-if="curr_view==='svm-exercise3'">
      <h4 class="h4-code">SVM C Parameter</h4>
      <pre>
        <code class="python">
          clf = SVC(kernel="rbf", C=10**5)
          clf.fit(features_train, labels_train)
          pred = clf.predict(features_test)

          %matplotlib inline
          prettyPicture(clf, features_test, labels_test)
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span> <span<img src="/img/images/svm_c_param.png">></span>
      </div>
    </div>

    <a href="" ng-click="click_view('svm-exercise4', 'svm')"><h3>Exercise 4: SVM gamma Parameter</h3></a>
    <div ng-if="curr_view==='svm-exercise4'">
      <h4 class="h4-code">SVM gamma Parameter</h4>
      <pre>
        <code class="python">
          clf = SVC(kernel="rbf", gamma=10)
          clf.fit(features_train, labels_train)
          pred = clf.predict(features_test)

          %matplotlib inline
          prettyPicture(clf, features_test, labels_test)
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span> <span><img src="/img/images/svm_gamma_param.png"></span>
      </div>
    </div>


    <a href="" ng-click="click_view('svm-exercise5', 'svm')"><h3>Exercise 5: SVM Author ID Accuracy & Timing</h3></a>
    <div ng-if="curr_view==='svm-exercise5'">
      <h4 class="h4-code">SVM Author ID Accuracy & Timing</h4>
      <pre>
        <code class="python">

          #!/usr/bin/python

          """ 
              This is the code to accompany the Lesson 2 (SVM) mini-project.

              Use a SVM to identify emails from the Enron corpus by their authors:    
              Sara has label 0
              Chris has label 1
          """
          from sklearn.metrics import accuracy_score

          from time import time
          from email_preprocess import preprocess


          ### features_train and features_test are the features for the training
          ### and testing datasets, respectively
          ### labels_train and labels_test are the corresponding item labels
          features_train, features_test, labels_train, labels_test = preprocess()


          def my_svm(features_train, features_test, labels_train, labels_test, kernel='linear', C=1.0):
              # the classifier
              clf = SVC(kernel=kernel, C=C)

              # train
              t0 = time()
              clf.fit(features_train, labels_train)
              print "\ntraining time:", round(time()-t0, 3), "s"

              # predict
              t0 = time()
              pred = clf.predict(features_test)
              print "predicting time:", round(time()-t0, 3), "s"

              accuracy = accuracy_score(pred, labels_test)

              print '\naccuracy = {0}'.format(accuracy)
              return pred

          pred = my_svm(features_train, features_test, labels_train, labels_test)
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b></span>
        <pre class="comment">
          <code>
            No. of Chris Training emails: 7936
            No. of Sara Training emails: 7884

            Training time: 176.156 s
            Predicting time: 18.561 s

            Accuracy = 0.984072810011
          </code>
        </pre>
        <span></span>
      </div>
    </div>

    <a href="" ng-click="click_view('svm-exercise6', 'svm')"><h3>Exercise 6: A Smaller Training Set</h3></a>
    <div ng-if="curr_view==='svm-exercise6'">
      <h4 class="h4-code">A Smaller Training Set</h4>
      <pre>
        <code class="python">
          features_train2 = features_train[:len(features_train)/100] 
          labels_train2 = labels_train[:len(labels_train)/100] 

          pred = my_svm(features_train2, features_test, labels_train2, labels_test)
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span> <span></span>
        <pre class="comment">
          <code>
            Training time: 0.124 s
            Predicting time: 1.123 s

            Accuracy = 0.884527872582
          </code>
        </pre>
      </div>
    </div>

    <a href="" ng-click="click_view('svm-exercise7', 'svm')"><h3>Exercise 7: Deploy an RBF Kernel</h3></a>
    <div ng-if="curr_view==='svm-exercise7'">
      <h4 class="h4-code">Deploy an RBF Kernel</h4>
      <pre>
        <code class="python">
          pred = my_svm(features_train2, features_test, labels_train2, labels_test, 'rbf')
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span> <span></span>
        <pre class="comment">
          <code>
            Training time: 0.128 s
            Predicting time: 1.246 s

            Accuracy = 0.616040955631
          </code>
        </pre>
      </div>
    </div>


    <a href="" ng-click="click_view('svm-exercise8', 'svm')"><h3>Exercise 8: Optimize C Parameter</h3></a>
    <div ng-if="curr_view==='svm-exercise8'">
      <h4 class="h4-code">Optimize C Parameter</h4>
      <pre>
        <code class="python">
          for C in [10, 100, 1000, 10000]:
            print 'C =',C,
            pred = my_svm(features_train2, features_test, labels_train2, labels_test, kernel='rbf', C=C)
            print '\n\n'
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span> <span></span>
        <pre class="comment">
          <code>
            C = 10 
          Training time: 0.133 s
          Predicting time: 1.245 s

          accuracy = 0.616040955631



          C = 100 
          Training time: 0.109 s
          Predicting time: 1.244 s

          accuracy = 0.616040955631



          C = 1000 
          Training time: 0.109 s
          Predicting time: 1.19 s

          accuracy = 0.821387940842



          C = 10000 
          Training time: 0.11 s
          Predicting time: 1.006 s

          Accuracy = 0.892491467577
          </code>
        </pre>
      </div>
    </div>

    <a href="" ng-click="click_view('svm-exercise9', 'svm')"><h3>Exercise 9: Optimized RBF vs. Linear SVM: Accuracy</h3></a>
    <div ng-if="curr_view==='svm-exercise9'">
      <h4 class="h4-code">Optimized RBF vs. Linear SVM: Accuracy</h4>
      <pre>
        <code class="python">
          pred = my_svm(features_train, features_test, labels_train, labels_test, kernel='rbf', C=10000)
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span> <span></span>
        <pre class="comment">
          <code>
            Training time: 116.73 s
            Predicting time: 11.745 s

            Accuracy = 0.990898748578

            
          </code>
        </pre>
      </div>
    </div>

    <a href="" ng-click="click_view('svm-exercise10', 'svm')"><h3>Exercise 10: Extracting Predictions from an SVM</h3></a>
    <div ng-if="curr_view==='svm-exercise10'">
      <h4 class="h4-code">Extracting Predictions from an SVM</h4>
      <pre>
        <code class="python">
          print pred[10]
          print pred[26]
          print pred[50]
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span> <span></span>
        <pre class="comment">
          <code>
            print pred[10] = 1
            print pred[26] = 0
            print pred[50] = 1
          </code>
        </pre>
      </div>
    </div>  

    <a href="" ng-click="click_view('svm-exercise11', 'svm')"><h3>Exercise 11: How many Chris emails predicted?</h3></a>
    <div ng-if="curr_view==='svm-exercise11'">
      <h4 class="h4-code">How many Chris emails predicted?</h4>
      <pre>
        <code class="python">
          print sum(pred)
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span> 877<span></span>
      </div>
    </div>
  </div>
  <button type="button" class="btn btn-info set-block-b" data-toggle="collapse" data-target="#d_tree">Lesson 3: Decision Tree</button>
  <div id="d_tree" class="collapse">
    <a href="" ng-click="click_view('d_tree-exercise1', 'd_tree')"><h3>Exercise 1: Coding a Decision Tree</h3></a>
    <div ng-if="curr_view==='d_tree-exercise1'">
      <h4 class="h4-code">Coding a Decision Tree</h4>
      <pre>
        <code class="python">
          import sys
          sys.path.append("C:/Users/Jeff/udacity/Intro_to_Machine_Learning/ud120-projects/tools/")
          sys.path.append('C:/Users/Jeff/udacity/Intro_to_Machine_Learning/ud120-projects/choose_your_own')
          sys.path.append('C:/Users/Jeff/udacity/Intro_to_Machine_Learning/ud120-projects/svm')

          import os
          os.chdir('C:/Users/Jeff/udacity/Intro_to_Machine_Learning/ud120-projects/decision_tree')


          """ lecture and example code for decision tree unit """

          import sys
          from class_vis import prettyPicture, output_image
          from prep_terrain_data import makeTerrainData

          import matplotlib.pyplot as plt
          import numpy as np
          import pylab as pl

          from sklearn import tree

          features_train, labels_train, features_test, labels_test = makeTerrainData()


          #def classify(features_train, labels_train, **kwargs):
          #    clf = tree.DecisionTreeClassifier(**kwargs)
          #    clf = clf.fit(features_train, labels_train)
          #    return clf


          ### the classify() function in classifyDT is where the magic
          ### happens--it's your job to fill this in!
          clf = tree.DecisionTreeClassifier()
          clf = clf.fit(features_train, labels_train)



          #### grader code, do not modify below this line
          %matplotlib inline
          prettyPicture(clf, features_test, labels_test)
          #output_image("test.png", "png", open("test.png", "rb").read())
          
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span><img src="/img/images/coding_decision_tree.png"></span>
      </div>
    </div>

    <a href="" ng-click="click_view('d_tree-exercise2', 'd_tree')"><h3>Exercise 2: Decision Tree Accuracy</h3></a>
    <div ng-if="curr_view==='d_tree-exercise2'">
      <h4 class="h4-code">Decision Tree Accuracy</h4>
      <pre>
        <code class="python">
          features_train, labels_train, features_test, labels_test = makeTerrainData()

          ########################## DECISION TREE #################################


          ### your code goes here--now create 2 decision tree classifiers,
          ### one with min_samples_split=2 and one with min_samples_split=50
          ### compute the accuracies on the testing data and store
          ### the accuracy numbers to acc_min_samples_split_2 and
          ### acc_min_samples_split_50, respectively

          clf2 = tree.DecisionTreeClassifier(min_samples_split=2)
          clf2 = clf2.fit(features_train, labels_train)

          clf50 = tree.DecisionTreeClassifier(min_samples_split=50)
          clf50 = clf50.fit(features_train, labels_train)
          #clf50 = classify(features_train, labels_train, min_samples_split=50)
          #clf = tree.DecisionTreeClassifier(min_samples_split=50).fit(features_train, labels_train)

          acc_min_samples_split_2 = clf2.score(features_test, labels_test)
          acc_min_samples_split_50 = clf50.score(features_test, labels_test)
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span>0.908</span>
      </div>
    </div>

    <a href="" ng-click="click_view('d_tree-exercise3', 'd_tree')"><h3>Exercise 3: Entropy Calculation Part 5</h3></a>
    <div ng-if="curr_view==='d_tree-exercise3'">
      <h4 class="h4-code">Entropy Calculation Part 5</h4>
      <pre>
        <code class="python">
          import scipy.stats

          pk = [0.5, 0.5]
          print scipy.stats.entropy(pk, base=2)
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span>1.0</span>
      </div>
    </div>

    <a href="" ng-click="click_view('d_tree-exercise4', 'd_tree')"><h3>Exercise 4: Information Gain Calculation Part 5</h3></a>
    <div ng-if="curr_view==='d_tree-exercise4'">
      <h4 class="h4-code">Information Gain Calculation Part 5</h4>
      <pre>
        <code class="python">
          print scipy.stats.entropy([1,2], base=2)
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span>0.918295834054</span>
      </div>
    </div>

    <a href="" ng-click="click_view('d_tree-exercise5', 'd_tree')"><h3>Exercise 5: Information Gain Calculation Part 6</h3></a>
    <div ng-if="curr_view==='d_tree-exercise5'">
      <h4 class="h4-code">Information Gain Calculation Part 6</h4>
      <pre>
        <code class="python">
          print 1-0.75*scipy.stats.entropy([1,2], base=2)
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span>0.311278124459</span>
      </div>
    </div>

    <a href="" ng-click="click_view('d_tree-exercise6', 'd_tree')"><h3>Exercise 6: Your First Email DT: Accuracy</h3></a>
    <div ng-if="curr_view==='d_tree-exercise6'">
      <h4 class="h4-code">Your First Email DT: Accuracy</h4>
      <pre>
        <code class="python">
          """ 
              This is the code to accompany the Lesson 3 (decision tree) mini-project.

              Use a Decision Tree to identify emails from the Enron corpus by author:    
              Sara has label 0
              Chris has label 1
          """
              
          from time import time
          from email_preprocess import preprocess


          ### features_train and features_test are the features for the training
          ### and testing datasets, respectively
          ### labels_train and labels_test are the corresponding item labels
          features_train, features_test, labels_train, labels_test = preprocess()




          #########################################################
          ### your code goes here ###
          clf = tree.DecisionTreeClassifier(min_samples_split=40)
          clf = clf.fit(features_train, labels_train)

          print clf.score(features_test, labels_test)
          
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span></span>
        <pre class="comment">
          <code>
            No. of Chris Training Emails: 7936
            No. of Sara Training Emails: 7884
            0.978384527873
          </code>
        </pre>
      </div>
    </div>

    <a href="" ng-click="click_view('d_tree-exercise7', 'd_tree')"><h3>Exercise 7: Speeding Up Via Feature Selection 1</h3></a>
    <div ng-if="curr_view==='d_tree-exercise7'">
      <h4 class="h4-code">Speeding Up Via Feature Selection 1</h4>
      <pre>
        <code class="python">
          print features_train.shape
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span>(15820L, 3785L)</span>
      </div>
    </div>

    <a href="" ng-click="click_view('d_tree-exercise8', 'd_tree')"><h3>Exercise 8: Changing the Number of Features</h3></a>
    <div ng-if="curr_view==='d_tree-exercise8'">
      <h4 class="h4-code">Changing the Number of Features</h4>
      <pre>
        <code class="python">
          # I made "percentile" an input argument for preprocess with default value 10
          features_train, features_test, labels_train, labels_test = preprocess(percentile=1)
          print features_train.shape
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span></span>
        <pre class="comment">
          <code>
            No. of Chris Training emails: 7936
            No. of Sara Training emails: 7884
            (15820L, 379L)
          </code>
        </pre>
      </div>
    </div>

    <a href="" ng-click="click_view('d_tree-exercise9', 'd_tree')"><h3>Exercise 9: Accuracy Using 1% of Features</h3></a>
    <div ng-if="curr_view==='d_tree-exercise9'">
      <h4 class="h4-code">Accuracy Using 1% of Features</h4>
      <pre>
        <code class="python">
          clf = tree.DecisionTreeClassifier(min_samples_split=40)
          clf = clf.fit(features_train, labels_train)

          print clf.score(features_test, labels_test)
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span>0.967007963595</span>
      </div>
    </div>    
  </div>

  <button type="button" class="btn btn-info set-block-b" data-toggle="collapse" data-target="#own_algo">Lesson 4: Choose Your Own Algorithm</button>
  <div id="own_algo" class="collapse">
    <br>
    <a href="" ng-click="click_view('own_algo-exercise1', 'own_algo')"><h3>Exercise 1: Choose Your Own Algorithm</h3></a>
    <div ng-if="curr_view==='own_algo-exercise1'">
      <h4 class="h4-code">Choose Your Own Algorithm</h4>
      <pre>
        <code class="python">
          import sys
          sys.path.append("C:/Users/Jeff/udacity/Intro_to_Machine_Learning/ud120-projects/tools/")
          sys.path.append('C:/Users/Jeff/udacity/Intro_to_Machine_Learning/ud120-projects/choose_your_own')

          import os
          os.chdir('C:/Users/Jeff/udacity/Intro_to_Machine_Learning/ud120-projects/choose_your_own')


          import matplotlib.pyplot as plt
          from prep_terrain_data import makeTerrainData
          from class_vis import prettyPicture

          features_train, labels_train, features_test, labels_test = makeTerrainData()


          ### the training data (features_train, labels_train) have both "fast" and "slow"
          ### points mixed together--separate them so we can give them different colors
          ### in the scatterplot and identify them visually
          grade_fast = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==0]
          bumpy_fast = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==0]
          grade_slow = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==1]
          bumpy_slow = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==1]


          #### initial visualization
          %matplotlib inline
          plt.xlim(0.0, 1.0)
          plt.ylim(0.0, 1.0)
          plt.scatter(bumpy_fast, grade_fast, color = "b", label="fast")
          plt.scatter(grade_slow, bumpy_slow, color = "r", label="slow")
          plt.legend()
          plt.xlabel("bumpiness")
          plt.ylabel("grade")
          plt.show()
          ################################################################################


          ### your code here!  name your classifier object clf if you want the 
          ### visualization code (prettyPicture) to show you the decision boundary

          # import the classifiers
          from sklearn.neighbors import KNeighborsClassifier
          from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier
          from sklearn.tree import DecisionTreeClassifier
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span><img src="/img/images/choosing_own_algo.png"></span>
      </div>
    </div>

    <a href="" ng-click="click_view('own_algo-exercise2', 'own_algo')"><h3>Exercise 2: kNN</h3></a>
    <div ng-if="curr_view==='own_algo-exercise2'">
      <h4 class="h4-code">kNN</h4>
      <pre>
        <code class="python">
          clf = KNeighborsClassifier(n_neighbors=1)
          clf.fit(features_train, labels_train)

          # print the accuracy and display the decision boundary
          print 'Accuracy = {0}'.format(clf.score(features_test, labels_test))
          prettyPicture(clf, features_test, labels_test)
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span><img src="/img/images/choosing_own_algo_knn.png"></span>
      </div>
    </div>

    <a href="" ng-click="click_view('own_algo-exercise3', 'own_algo')"><h3>Exercise 3: Random Forest</h3></a>
    <div ng-if="curr_view==='own_algo-exercise3'">
      <h4 class="h4-code">Random Forest</h4>
      <pre>
        <code class="python">
          clf = RandomForestClassifier(n_estimators=100)
          clf = clf.fit(features_train, labels_train)

          # print the accuracy and display the decision boundary
          print 'Accuracy = {0}'.format(clf.score(features_test, labels_test))
          prettyPicture(clf, features_test, labels_test)
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span><img src="/img/images/choosing_own_algo_rf.png"></span>
      </div>
    </div>

    <a href="" ng-click="click_view('own_algo-exercise4', 'own_algo')"><h3>Exercise 4: AdaBoost</h3></a>
    <div ng-if="curr_view==='own_algo-exercise4'">
      <h4 class="h4-code">AdaBoost</h4>
      <pre>
        <code class="python">
          clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=200)
          clf = clf.fit(features_train, labels_train)

          # print the accuracy and display the decision boundary
          print 'Accuracy = {0}'.format(clf.score(features_test, labels_test))
          prettyPicture(clf, features_test, labels_test)
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span><img src="/img/images/choosing_own_algo_adaboost.png"></span>
      </div>
    </div>
  </div>
  <button type="button" class="btn btn-info set-block-b" data-toggle="collapse" data-target="#dataset">Lesson 5: Datasets and Question</button>
  <div id="dataset" class="collapse">
    <a href="" ng-click="click_view('dataset-exercise1', 'dataset')"><h3>Exercise 1: Size of the Enron Dataset</h3></a>
    <div ng-if="curr_view==='dataset-exercise1'">
      <h4 class="h4-code">Size of the Enron Dataset</h4>
      <pre>
        <code class="python">
          import sys
          sys.path.append("C:/Users/Jeff/udacity/Intro_to_Machine_Learning/ud120-projects/tools/")
          sys.path.append('C:/Users/Jeff/udacity/Intro_to_Machine_Learning/ud120-projects/choose_your_own')
          sys.path.append('C:/Users/Jeff/udacity/Intro_to_Machine_Learning/ud120-projects/datasets_questions')

          import os
          os.chdir('C:/Users/Jeff/udacity/Intro_to_Machine_Learning/ud120-projects/datasets_questions')

          import pickle

          enron_data = pickle.load(open("../final_project/final_project_dataset.pkl", "r"))
          print 'Number of people in the Enron dataset: {0}'.format(len(enron_data))
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span></span>
        <pre class="comment">
          <code>
            Number of people in the Enron dataset: 146
          </code>
        </pre>
      </div>
    </div>

    <a href="" ng-click="click_view('dataset-exercise2', 'dataset')"><h3>Exercise 2: Features in the Enron Dataset</h3></a>
    <div ng-if="curr_view==='dataset-exercise2'">
      <h4 class="h4-code">Features in the Enron Dataset</h4>
      <pre>
        <code class="python">
          print 'Number of features for each person in the Enron dataset: {0}'.format(len(enron_data.values()[0]))
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span></span>
        <pre class="comment">
          <code>
            Number of features for each person in the Enron dataset: 21
          </code>
        </pre>
      </div>
    </div>

    <a href="" ng-click="click_view('dataset-exercise3', 'dataset')"><h3>Exercise 3: Finding POI's in the Enron Data</h3></a>
    <div ng-if="curr_view==='dataset-exercise3'">
      <h4 class="h4-code">Finding POI's in the Enron Data</h4>
      <pre>
        <code class="python">
          pois = [x for x, y in enron_data.items() if y['poi']]
          print 'Number of POI\'s: {0}'.format(len(pois))
          #enron_data.items()[0]
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span></span>
        <pre class="comment">
          <code>
            Number of POI's: 18
          </code>
        </pre>
      </div>
    </div>


    <a href="" ng-click="click_view('dataset-exercise4', 'dataset')"><h3>Exercise 4: Query the Dataset 1</h3></a>
    <div ng-if="curr_view==='dataset-exercise4'">
      <h4 class="h4-code">Query the Dataset 1</h4>
      <pre>
        <code class="python">
          # DELETE ME
          enron_data['PRENTICE JAMES']
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span></span>
        <pre class="comment">
          <code>{
             'bonus': 'NaN',
             'deferral_payments': 564348,
             'deferred_income': 'NaN',
             'director_fees': 'NaN',
             'email_address': 'james.prentice@enron.com',
             'exercised_stock_options': 886231,
             'expenses': 'NaN',
             'from_messages': 'NaN',
             'from_poi_to_this_person': 'NaN',
             'from_this_person_to_poi': 'NaN',
             'loan_advances': 'NaN',
             'long_term_incentive': 'NaN',
             'other': 'NaN',
             'poi': False,
             'restricted_stock': 208809,
             'restricted_stock_deferred': 'NaN',
             'salary': 'NaN',
             'shared_receipt_with_poi': 'NaN',
             'to_messages': 'NaN',
             'total_payments': 564348,
             'total_stock_value': 1095040
            }
          </code>
        </pre>
      </div>
      <pre>
        <code class="python">
          enron_data['PRENTICE JAMES']['total_stock_value']
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span>1095040</span>
      </div>
    </div>

    <a href="" ng-click="click_view('dataset-exercise5', 'dataset')"><h3>Exercise 5: Query the Dataset 2</h3></a>
    <div ng-if="curr_view==='dataset-exercise5'">
      <h4 class="h4-code">Query the Dataset 2</h4>
      <pre>
        <code class="python">
          enron_data['COLWELL WESLEY']['from_this_person_to_poi']
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span>11</span>
      </div>
    </div>

    <a href="" ng-click="click_view('dataset-exercise6', 'dataset')"><h3>Exercise 6: Query the Dataset 3</h3></a>
    <div ng-if="curr_view==='dataset-exercise6'">
      <h4 class="h4-code">Query the Dataset 3</h4>
      <pre>
        <code class="python">
          enron_data['SKILLING JEFFREY K']['exercised_stock_options']
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span>19250000</span>
      </div>
    </div>

    <a href="" ng-click="click_view('dataset-exercise7', 'dataset')"><h3>Exercise 7: Follow the Money</h3></a>
    <div ng-if="curr_view==='dataset-exercise7'">
      <h4 class="h4-code">Follow the Money</h4>
      <pre>
        <code class="python">
          names = ['SKILLING JEFFREY K', 'FASTOW ANDREW S', 'LAY KENNETH L']
          names_payments = {name:enron_data[name]['total_payments'] for name in names}
          print sorted(names_payments.items(), key=lambda x: x[1], reverse=True)
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span></span>
        <pre class="comment">
          <code>
            [('LAY KENNETH L', 103559793), ('SKILLING JEFFREY K', 8682716), ('FASTOW ANDREW S', 2424083)]
          </code>
        </pre>
      </div>
    </div>

    <a href="" ng-click="click_view('dataset-exercise8', 'dataset')"><h3>Exercise 8: Dealing with Unfilled Features</h3></a>
    <div ng-if="curr_view==='dataset-exercise8'">
      <h4 class="h4-code">Dealing with Unfilled Features</h4>
      <pre>
        <code class="python">
          import pandas as pd

          df = pd.DataFrame(enron_data)
          print 'Has salary data: {0}'.format(sum(df.loc['salary',:] != 'NaN'))
          print 'Has email: {0}'.format(sum(df.loc['email_address',:] != 'NaN'))
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span></span>
        <pre class="comment">
          <code>
            Has salary data: 95
            Has email: 111
          </code>
        </pre>
      </div>
    </div>

    <a href="" ng-click="click_view('dataset-exercise9', 'dataset')"><h3>Exercise 9: Missing POI's 1</h3></a>
    <div ng-if="curr_view==='dataset-exercise9'">
      <h4 class="h4-code">Missing POI's 1</h4>
      <pre>
        <code class="python">
          # How many people in the E+F dataset (as it currently exists) have “NaN” for their total payments? 
          # What percentage of people in the dataset as a whole is this?

          isnan = sum(df.loc['total_payments',:]=='NaN')
          _,cols = df.shape
          print 'total_payments == \'NaN\': {0} people = {1:.2f}%'.format(isnan, 100.*isnan/cols)
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span></span>
        <pre class="comment">
          <code>
            total_payments == 'NaN': 21 people = 14.38%
          </code>
        </pre>
      </div>
    </div>

    <a href="" ng-click="click_view('dataset-exercise10', 'dataset')"><h3>Exercise 10: Missing POI's 2</h3></a>
    <div ng-if="curr_view==='dataset-exercise10'">
      <h4 class="h4-code">Missing POI's 2</h4>
      <pre>
        <code class="python">
          isnan = sum(df.loc['total_payments',pois]=='NaN')
          print 'POI total_payments == \'NaN\': {0} people = {1:.2f}%'.format(isnan, 100.*isnan/len(pois))
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span></span>
        <pre class="comment">
          <code>
            POI total_payments == 'NaN': 0 people = 0.00%
          </code>
        </pre>
      </div>
    </div>

  </div>
  <button type="button" class="btn btn-info set-block-b" data-toggle="collapse" data-target="#regression">Lesson 6: Regressions</button>
  <div id="regression" class="collapse">
    <a href="" ng-click="click_view('regression-exercise1', 'regression')"><h3>Exercise 1: Age/Net Worth Regression in sklearn</h3></a>
    <div ng-if="curr_view==='regression-exercise1'">
      <h4 class="h4-code">Age/Net Worth Regression in sklearn</h4>
      <pre>
        <code class="python">
          import sys
          sys.path.append("C:/Users/Jeff/udacity/Intro_to_Machine_Learning/ud120-projects/tools/")
          sys.path.append('C:/Users/Jeff/udacity/Intro_to_Machine_Learning/ud120-projects/choose_your_own')
          sys.path.append('C:/Users/Jeff/udacity/Intro_to_Machine_Learning/ud120-projects/datasets_questions')

          import os
          os.chdir('C:/Users/Jeff/udacity/Intro_to_Machine_Learning/ud120-projects/regression')


          import numpy
          import matplotlib
          matplotlib.use('agg')

          import matplotlib.pyplot as plt
          from class_vis import prettyPicture, output_image

          from ages_net_worths import ageNetWorthData

          ages_train, ages_test, net_worths_train, net_worths_test = ageNetWorthData()


          from sklearn import linear_model

          def studentReg(ages_train, net_worths_train):
              reg = linear_model.LinearRegression()
              reg.fit(ages_train, net_worths_train)
              return reg


          reg = studentReg(ages_train, net_worths_train)

          %matplotlib inline
          plt.clf()
          plt.scatter(ages_train, net_worths_train, color="b", label="train data")
          plt.scatter(ages_test, net_worths_test, color="r", label="test data")
          plt.plot(ages_test, reg.predict(ages_test), color="black")
          plt.legend(loc=2)
          plt.xlabel("ages")
          plt.ylabel("net worths")
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span><img src="img/images/regression.png"></span>
      </div>
    </div>

    <a href="" ng-click="click_view('regression-exercise2', 'regression')"><h3>Exercise 2: Now You Practice Extracting Information</h3></a>
    <div ng-if="curr_view==='regression-exercise2'">
      <h4 class="h4-code">Now You Practice Extracting Information</h4>
      <pre>
        <code class="python">
          reg = linear_model.LinearRegression()
          reg.fit(ages_train, net_worths_train)

          ### get Katie's net worth (she's 27)
          ### sklearn predictions are returned in an array, so you'll want to index into
          ### the output to get what you want, e.g. net_worth = predict([[27]])[0][0] (not
          ### exact syntax, the point is the [0] at the end). In addition, make sure the
          ### argument to your prediction function is in the expected format - if you get
          ### a warning about needing a 2d array for your data, a list of lists will be
          ### interpreted by sklearn as such (e.g. [[27]]).
          km_net_worth = reg.predict([[27]])[0][0]

          ### get the slope
          ### again, you'll get a 2-D array, so stick the [0][0] at the end
          slope = reg.coef_[0][0]

          ### get the intercept
          ### here you get a 1-D array, so stick [0] on the end to access
          ### the info we want
          intercept = reg.intercept_[0]


          ### get the score on test data
          test_score = reg.score(ages_test, net_worths_test)


          ### get the score on the training data
          training_score = reg.score(ages_train, net_worths_train)
        </code>
      </pre>
    </div>

    <a href="" ng-click="click_view('regression-exercise3', 'regression')"><h3>Exercise 3: Bonus Target and Features</h3></a>
    <div ng-if="curr_view==='regression-exercise3'">
      <h4 class="h4-code">Bonus Target and Features</h4>
      <pre>
        <code class="python">
          import pickle
          from feature_format import featureFormat, targetFeatureSplit

          dictionary = pickle.load( open("../final_project/final_project_dataset_modified.pkl", "r") )

          def finance_regression(dictionary, features_list, fit_test=False):
              data = featureFormat( dictionary, features_list, remove_any_zeroes=True)
              target, features = targetFeatureSplit( data )

              ### training-testing split needed in regression, just like classification
              from sklearn.cross_validation import train_test_split
              feature_train, feature_test, target_train, target_test = train_test_split(features, target, test_size=0.5, random_state=42)
              train_color = "b"
              test_color = "r"


              reg = linear_model.LinearRegression()
              reg.fit(feature_train, target_train)


              ### draw the scatterplot, with color-coded training and testing points
              import matplotlib.pyplot as plt
              for feature, target in zip(feature_test, target_test):
                  plt.scatter( feature, target, color=test_color ) 
              for feature, target in zip(feature_train, target_train):
                  plt.scatter( feature, target, color=train_color ) 

              ### labels for the legend
              plt.scatter(feature_test[0], target_test[0], color=test_color, label="test")
              plt.scatter(feature_test[0], target_test[0], color=train_color, label="train")


              # draw the regression line, once it's coded
              plt.plot( feature_test, reg.predict(feature_test) )
              plt.xlabel(features_list[1])
              plt.ylabel(features_list[0])
              plt.legend()
              
              if fit_test:
                  reg.fit(feature_test, target_test)
                  plt.plot(feature_train, reg.predict(feature_train), color="r") 
              
              return (reg, feature_train, target_train, feature_test, target_test)


          (reg, feature_train, target_train, feature_test, target_test) = finance_regression(dictionary, ["bonus", "salary"])
          
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span><img src="/img/images/regression_bonus_target.png"></span>
      </div>
    </div>

    <a href="" ng-click="click_view('regression-exercise4', 'regression')"><h3>Exercise 4: Extracting Slope and Intercept</h3></a>
    <div ng-if="curr_view==='regression-exercise4'">
      <h4 class="h4-code">Extracting Slope and Intercept</h4>
      <pre>
        <code class="python">
          print 'slope = {0}'.format(reg.coef_[0])
          print 'intercept = {0}'.format(reg.intercept_)
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span></span>
        <pre class="comment">
          <code>
            slope = 5.44814028881
            intercept = -102360.543294
          </code>
        </pre>
      </div>
    </div>

    <a href="" ng-click="click_view('regression-exercise5', 'regression')"><h3>Exercise 5: Regression Score: Training Data</h3></a>
    <div ng-if="curr_view==='regression-exercise5'">
      <h4 class="h4-code">Regression Score: Training Data</h4>
      <pre>
        <code class="python">
          print 'score on training set = {0}'.format(reg.score(feature_train, target_train))          
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span></span>
        <pre class="comment">
          <code>
            score on training set = 0.0455091926995            
          </code>
        </pre>
      </div>
    </div>

    <a href="" ng-click="click_view('regression-exercise6', 'regression')"><h3>Exercise 6: Regression Score: Test Data</h3></a>
    <div ng-if="curr_view==='regression-exercise6'">
      <h4 class="h4-code">Regression Score: Test Data</h4>
      <pre>
        <code class="python">
          print 'score on test set = {0}'.format(reg.score(feature_test, target_test))          
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span></span>
        <pre class="comment">
          <code>
            score on test set = -1.48499241737            
          </code>
        </pre>
      </div>
    </div>

    <a href="" ng-click="click_view('regression-exercise7', 'regression')"><h3>Exercise 7: Regressing Bonus Against LTI</h3></a>
    <div ng-if="curr_view==='regression-exercise7'">
      <h4 class="h4-code">Regressing Bonus Against LTI</h4>
      <pre>
        <code class="python">
          (reg, feature_train, target_train, feature_test, target_test) = finance_regression(dictionary, ['bonus', 'long_term_incentive'])          
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span><img src="img/images/regression_bonus_against_lti.png"></span>
      </div>
    </div>

    <a href="" ng-click="click_view('regression-exercise8', 'regression')"><h3>Exercise 8: Sneak Peek: Outliers Break Regressions</h3></a>
    <div ng-if="curr_view==='regression-exercise8'">
      <h4 class="h4-code">Sneak Peek: Outliers Break Regressions</h4>
      <pre>
        <code class="python">
          (reg, feature_train, target_train, feature_test, target_test) = finance_regression(dictionary, ["bonus", "salary"], fit_test=True)
          print 'slope = {0}'.format(reg.coef_[0])
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span><img src="/img/images/regression_bonus_slope.png"></span>
        <pre class="comment">
          <code>
            slope = 2.27410114127
          </code>
        </pre>
      </div>
    </div>
  </div>


  <button type="button" class="btn btn-info set-block-b" data-toggle="collapse" data-target="#outliers">Lesson 7: Outliers</button>
  <div id="outliers" class="collapse">
    <a href="" ng-click="click_view('outliers-exercise1', 'outliers')"><h3>Exercise 1: Slope of Regression with Outliers</h3></a>
    <div ng-if="curr_view==='outliers-exercise1'">
      <h4 class="h4-code">Slope of Regression with Outliers</h4>
      <pre>
        <code class="python">
          import sys
          sys.path.append("C:/Users/Jeff/udacity/Intro_to_Machine_Learning/ud120-projects/tools/")
          sys.path.append('C:/Users/Jeff/udacity/Intro_to_Machine_Learning/ud120-projects/choose_your_own')
          sys.path.append('C:/Users/Jeff/udacity/Intro_to_Machine_Learning/ud120-projects/datasets_questions')

          import os
          os.chdir('C:/Users/Jeff/udacity/Intro_to_Machine_Learning/ud120-projects/outliers')

          import random
          import numpy
          import matplotlib.pyplot as plt
          import pickle

          from outlier_cleaner import outlierCleaner


          ### load up some practice data with outliers in it
          ages = pickle.load( open("practice_outliers_ages.pkl", "r") )
          net_worths = pickle.load( open("practice_outliers_net_worths.pkl", "r") )

          ### ages and net_worths need to be reshaped into 2D numpy arrays
          ### second argument of reshape command is a tuple of integers: (n_rows, n_columns)
          ### by convention, n_rows is the number of data points
          ### and n_columns is the number of features
          ages       = numpy.reshape( numpy.array(ages), (len(ages), 1))
          net_worths = numpy.reshape( numpy.array(net_worths), (len(net_worths), 1))
          from sklearn.cross_validation import train_test_split
          ages_train, ages_test, net_worths_train, net_worths_test = train_test_split(ages, net_worths, test_size=0.1, random_state=42)


          # fit a linear regression
          from sklearn import linear_model

          reg = linear_model.LinearRegression()
          reg.fit(ages_train, net_worths_train)

          print 'slope = {0}'.format(reg.coef_[0][0])


          %matplotlib inline
          plt.plot(ages, reg.predict(ages), color="blue")
          plt.scatter(ages, net_worths)
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span><img src="img/images/outliers_slope.png"></span>
        <pre class="comment">
          <code>
            slope = 5.07793064344
          </code>
        </pre>
      </div>
    </div>

    <a href="" ng-click="click_view('outliers-exercise1', 'outliers')"><h3>Exercise 2: Score of Regression with Outliers</h3></a>
    <div ng-if="curr_view==='outliers-exercise2'">
      <h4 class="h4-code">Score of Regression with Outliers</h4>
      <pre>
        <code class="python">
          print 'score = {0}'.format(reg.score(ages_test, net_worths_test))
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span></span>
        <pre class="comment">
          <code>
            score = 0.878262478835
          </code>
        </pre>
      </div>
    </div>

    <a href="" ng-click="click_view('outliers-exercise1', 'outliers')"><h3>Exercise 3: Slope After Cleaning</h3></a>
    <div ng-if="curr_view==='outliers-exercise3'">
      <h4 class="h4-code">Slope After Cleaning</h4>
      <pre>
        <code class="python">
          def outlierCleaner(predictions, ages, net_worths):
              """
                  Clean away the 10% of points that have the largest
                  residual errors (difference between the prediction
                  and the actual net worth).

                  Return a list of tuples named cleaned_data where 
                  each tuple is of the form (age, net_worth, error).
              """
              errors = net_worths-predictions
              threshold = numpy.percentile(numpy.absolute(errors), 90)
              #print threshold
              #print numpy.max(numpy.absolute(errors))
              #print numpy.sort(numpy.absolute(errors), axis=0)
              
              cleaned_data = [(age, net_worth, error) for age, net_worth, error in zip(ages, net_worths, errors) if abs(error) <= threshold]
              
              return cleaned_data

          reg = linear_model.LinearRegression()
          reg.fit(ages_train, net_worths_train)

          plt.plot(ages, reg.predict(ages), color='blue')

          # plot all points in blue
          plt.scatter(ages, net_worths, color='blue')

          # plot the current training points in orange
          plt.scatter(ages_train, net_worths_train, color='orange')

          ### identify and remove the most outlier-y points
          predictions = reg.predict(ages_train)
          cleaned_data = outlierCleaner( predictions, ages_train, net_worths_train )


          ### only run this code if cleaned_data is returning data
          if len(cleaned_data) > 0:
              # the non-outlier ages, net worths, and errors
              ages_train2, net_worths_train2, errors_train2 = zip(*cleaned_data)
              ages_train2       = numpy.reshape( numpy.array(ages_train2), (len(ages_train2), 1))
              net_worths_train2 = numpy.reshape( numpy.array(net_worths_train2), (len(net_worths_train2), 1))

              # refit the cleaned data
              reg2 = linear_model.LinearRegression()
              reg2.fit(ages_train2, net_worths_train2)
              plt.plot(ages, reg2.predict(ages), color='red')
              plt.scatter(ages_train2, net_worths_train2, color='red')
              plt.xlabel("ages")
              plt.ylabel("net worths")

          else:
              print "outlierCleaner() is returning an empty list, no refitting to be done"
              
              
          print 'new slope = {0}'.format(reg2.coef_[0][0])

        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span><img src="img/images/slope_after_cleaning.png"></span>
        <pre class="comment">
          <code>
            new slope = 6.36859480694
          </code>
        </pre>
      </div>
    </div>

    <a href="" ng-click="click_view('outliers-exercise1', 'outliers')"><h3>Exercise 4: Score After Cleaning</h3></a>
    <div ng-if="curr_view==='outliers-exercise4'">
      <h4 class="h4-code">Score After Cleaning</h4>
      <pre>
        <code class="python">
          print 'new score = {0}'.format(reg2.score(ages_test, net_worths_test))
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span></span>
        <pre class="comment">
          <code>
            new score = 0.983189455686
          </code>
        </pre>
      </div>
    </div>

    <a href="" ng-click="click_view('outliers-exercise1', 'outliers')"><h3>Exercise 5: Enron Outliers</h3></a>
    <div ng-if="curr_view==='outliers-exercise5'">
      <h4 class="h4-code">Enron Outliers</h4>
      <pre>
        <code class="python">
          from feature_format import featureFormat, targetFeatureSplit

          ### read in data dictionary, convert to numpy array
          data_dict = pickle.load( open("../final_project/final_project_dataset.pkl", "r") )
          features = ["salary", "bonus"]
          data = featureFormat(data_dict, features)

          plt.scatter(data[:,0], data[:,1])
          plt.xlabel("salary")
          plt.ylabel("bonus")

          import pandas as pd
          df = pd.DataFrame(data_dict)
          df.loc['salary',:] = pd.to_numeric(df.loc['salary',:], errors='coerce')
          df.loc['bonus',:] = pd.to_numeric(df.loc['bonus',:], errors='coerce')

          print df.loc['salary',:].idxmax(axis=1)
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span><img src="img/images/enron_outliers.png"></span>
        <pre class="comment">
          <code>
            Outlier name: TOTAL
          </code>
        </pre>
      </div>
    </div>

    <a href="" ng-click="click_view('outliers-exercise1', 'outliers')"><h3>Exercise 6: Any More Outliers?</h3></a>
    <div ng-if="curr_view==='outliers-exercise6'">
      <h4 class="h4-code">Any More Outliers?</h4>
      <pre>
        <code class="python">
          data_dict.pop('TOTAL', 0)

          data = featureFormat(data_dict, features)

          plt.scatter(data[:,0], data[:,1])
          plt.xlabel("salary")
          plt.ylabel("bonus")
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span><img src="img/images/any_more_outlier.png"></span>
        </pre>
      </div>
    </div>

    <a href="" ng-click="click_view('outliers-exercise1', 'outliers')"><h3>Exercise 7: Identifying Two More Outliers</h3></a>
    <div ng-if="curr_view==='outliers-exercise7'">
      <h4 class="h4-code">Identifying Two More Outliers</h4>
      <pre>
        <code class="python">
          #print df.columns[name wdf.loc['salary',:] > 1*10**6 and df.loc['bonus',:] > 5*10**6]
          print [name for name in df.columns if df.loc['salary', name] > 10**6 and df.loc['bonus',name] > 5*10**6]
        </code>
      </pre>
      <div class="code-output">
        <span class='output-title'><b>Output:</b> </span><span></span>
        <pre class="comment">
          <code>
            ['LAY KENNETH L', 'SKILLING JEFFREY K', 'TOTAL']
          </code>
        </pre>
      </div>
    </div>

  </div>
  <button type="button" class="btn btn-info set-block-b" data-toggle="collapse" data-target="#naive_bayes">Lesson 8: Clustering</button>
  <div id="clustering" class="collapse"></div>
  <button type="button" class="btn btn-info set-block-b" data-toggle="collapse" data-target="#naive_bayes">Lesson 9: Feature Scaling</button>
  <div id="f_scaling" class="collapse"></div>
  <button type="button" class="btn btn-info set-block-b" data-toggle="collapse" data-target="#naive_bayes">Lesson 10: Text Learning</button>
  <div id="text_learning" class="collapse"></div>
  <button type="button" class="btn btn-info set-block-b" data-toggle="collapse" data-target="#naive_bayes">Lesson 11: Feature Selection</button>
  <div id="feature_selection" class="collapse"></div>
  <button type="button" class="btn btn-info set-block-b" data-toggle="collapse" data-target="#naive_bayes">Lesson 12: PCA</button>
  <div id="pca" class="collapse"></div>
  <button type="button" class="btn btn-info set-block-b" data-toggle="collapse" data-target="#naive_bayes">Lesson 13: Validation</button>
  <div id="validation" class="collapse"></div>
  <button type="button" class="btn btn-info set-block-b" data-toggle="collapse" data-target="#naive_bayes">Lesson 14: Evaluation Metrices</button>
  <div id="evaluation_metrices" class="collapse"></div>
  <button type="button" class="btn btn-info set-block-b" data-toggle="collapse" data-target="#naive_bayes">Lesson 15: Final Project</button>
  <div id="final_project" class="collapse"></div>
</div>


<!-- <div class="container">
  <div class="row">
    <div class="col-lg-8 col-md-10 mx-auto">
      <p>For those who have seen the Earth from space, and for the hundreds and perhaps thousands more who will, the experience most certainly changes your perspective. The things that we share in our world are far more valuable than those which divide us.</p>

      <h2 class="section-heading">The Final Frontier</h2>

      <p> </p>
      <blockquote class="blockquote">The dreams of yesterday are the hopes of today and the reality of tomorrow. Science has not yet mastered prophecy. We predict too much for the next year and yet far too little for the next ten.</blockquote>
      <h2 class="section-heading">Reaching for the Stars</h2>

      <p> has to change a man.</p>

      <span class="caption text-muted">To go places and do things that have never been done before – that’s what living is all about.</span>
    </div>
  </div>
</div> -->
